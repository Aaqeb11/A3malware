from tkinter import messagebox
from tkinter import *
from tkinter.filedialog import askopenfilename
from tkinter import simpledialog
import tkinter
import numpy as np
from tkinter import filedialog
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt
from sklearn.naive_bayes import BernoulliNB
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import f1_score
from sklearn.metrics import accuracy_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn import svm
from keras.models import Sequential
from keras.layers import Convolution2D
from keras.layers import MaxPooling2D
from keras.layers import Flatten
from keras.layers import Dense, Activation, BatchNormalization, Dropout
from sklearn.preprocessing import OneHotEncoder
from keras.models import model_from_json
from keras.layers import LSTM
from keras.layers import Embedding
#from keras.layers.embeddings import Embedding
import keras
import tensorflow as tf
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, LSTM, Dropout, Activation
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score





from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import Normalizer
import keras.layers
from keras.models import model_from_json

main = tkinter.Tk() #Dialog window (create app window)
main.title("Robust Intelligent Malware Detection Using Deep Learning") #webapp title
main.geometry("1300x1200") #web app size

malware_name = ['Dialer Adialer.C', 'Backdoor Agent.FYI', 'Worm Allaple.A', 'Worm Allaple.L', 'Trojan Alueron.gen',
                'Worm:AutoIT Autorun.K',
                'Trojan C2Lop.P', 'Trojan C2Lop.gen', 'Dialer Dialplatform.B', 'Trojan Downloader Dontovo.A',
                'Rogue Fakerean', 'Dialer Instantaccess',
                'PWS Lolyda.AA 1', 'PWS Lolyda.AA 2', 'PWS Lolyda.AA 3', 'PWS Lolyda.AT', 'Trojan Malex.gen',
                'Trojan Downloader Obfuscator.AD',
                'Backdoor Rbot!gen', 'Trojan Skintrim.N', 'Trojan Downloader Swizzor.gen!E',
                'Trojan Downloader Swizzor.gen!I', 'Worm VB.AT',
                'Trojan Downloader Wintrim.BX', 'Worm Yuner.A'] #list
#global variable decleration
global filename
global knn_precision, nb_precision, tree_precision, svm_precision, random_precision, cnn_precision, lstm_precision
global knn_recall, nb_recall, tree_recall, svm_recall, random_recall, cnn_recall, lstm_recall
global knn_fmeasure, nb_fmeasure, tree_fmeasure, svm_fmeasure, random_fmeasure, cnn_fmeasure, lstm_fmeasure
global knn_acc, nb_acc, tree_acc, svm_acc, random_acc, cnn_acc, lstm_acc

global classifier
global X_train, X_test, y_train, y_test


def load_lstmcnn(dataset, standardize=True):
    features = dataset['arr'][:, 0]
    features = np.array([feature for feature in features])
    features = np.reshape(features, (features.shape[0], features.shape[1] * features.shape[2]))
    if standardize:
        features = StandardScaler().fit_transform(features)

    labels = dataset['arr'][:, 1]
    labels = np.array([label for label in labels])

    print(labels.shape)
    print(features.shape)

    return features, labels

# fits and shapes the dataset for prediction and further process
def load_data(dataset, standardize=True):
    features = dataset['arr'][:, 0]
    features = np.array([feature for feature in features])
    features = np.reshape(features, (features.shape[0], features.shape[1] * features.shape[2]))
    if standardize:
        features = StandardScaler().fit_transform(features)

    labels = dataset['arr'][:, 1]
    labels = np.array([label for label in labels])

    feature = []
    label = []
    for i in range(0, 4000):
        feature.append(features[i])
        label.append(labels[i])

    feature = np.asarray(feature)
    label = np.asarray(label)
    print(labels.shape)
    print(features.shape)
    print(label.shape)
    print(feature.shape)
    return feature, label

# assigning dataset name to filename variable
def upload():
    global filename
    filename = filedialog.askopenfilename(initialdir="dataset")
    pathlabel.config(text=filename)
    text.delete('1.0', END)
    text.insert(END, 'MalImg dataset loaded\n')


def prediction(X_test, cls):
    y_pred = cls.predict(X_test)
    for i in range(len(X_test)):
        print("X=%s, Predicted=%s" % (X_test[i], y_pred[i]))
    return y_pred


def KNN():
    global knn_precision
    global knn_recall
    global knn_fmeasure
    global knn_acc
    # text.delete('1.0', END)
    cls = KNeighborsClassifier(n_neighbors=10)
    cls.fit(X_train, y_train)
    text.insert(END, "\nKNN Prediction Results\n")
    prediction_data = prediction(X_test, cls)
    knn_precision = precision_score(y_test, prediction_data, average='micro') * 100
    knn_recall = recall_score(y_test, prediction_data, average='micro') * 100
    knn_fmeasure = f1_score(y_test, prediction_data, average='micro') * 100
    knn_acc = accuracy_score(y_test, prediction_data) * 100
    text.insert(END, "KNN Precision : " + str(knn_precision) + "\n")
    text.insert(END, "KNN Recall : " + str(knn_recall) + "\n")
    text.insert(END, "KNN FMeasure : " + str(knn_fmeasure) + "\n")
    text.insert(END, "KNN Accuracy : " + str(knn_acc) + "\n")
    # classifier = cls


def naivebayes():
    global nb_precision
    global nb_recall
    global nb_fmeasure
    global nb_acc
    # text.delete('1.0', END)
    data, labels = load_data(np.load(filename, allow_pickle=True))
    X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2)
    scaler = Normalizer().fit(X_train)
    X_train = scaler.transform(X_train)
    scaler = Normalizer().fit(X_test)
    X_test = scaler.transform(X_test)
    cls = BernoulliNB(binarize=0.0)
    cls.fit(X_train, y_train)
    text.insert(END, "\nNaive Bayes Prediction Results\n\n")
    prediction_data = prediction(X_test, cls)
    nb_precision = precision_score(y_test, prediction_data, average='micro') * 100
    nb_recall = recall_score(y_test, prediction_data, average='micro') * 100
    nb_fmeasure = f1_score(y_test, prediction_data, average='micro') * 100
    nb_acc = accuracy_score(y_test, prediction_data) * 100
    text.insert(END, "Naive Bayes Precision : " + str(nb_precision) + "\n")
    text.insert(END, "Naive Bayes Recall : " + str(nb_recall) + "\n")
    text.insert(END, "Naive Bayes FMeasure : " + str(nb_fmeasure) + "\n")
    text.insert(END, "Naive Bayes Accuracy : " + str(nb_acc) + "\n")


def decisionTree():
    # text.delete('1.0', END)
    global tree_acc
    global tree_precision
    global tree_recall
    global tree_fmeasure
    rfc = DecisionTreeClassifier(criterion="entropy", splitter="random", max_depth=20, min_samples_split=50,
                                 min_samples_leaf=20, max_features=5)
    rfc.fit(X_train, y_train)
    text.insert(END, "\nDecision Tree Prediction Results\n")
    prediction_data = prediction(X_test, rfc)
    tree_precision = precision_score(y_test, prediction_data, average='micro') * 100
    tree_recall = recall_score(y_test, prediction_data, average='micro') * 100
    tree_fmeasure = f1_score(y_test, prediction_data, average='micro') * 100
    tree_acc = accuracy_score(y_test, prediction_data) * 100
    text.insert(END, "Decision Tree Precision : " + str(tree_precision) + "\n")
    text.insert(END, "Decision Tree Recall : " + str(tree_recall) + "\n")
    text.insert(END, "Decision Tree FMeasure : " + str(tree_fmeasure) + "\n")
    text.insert(END, "Decision Tree Accuracy : " + str(tree_acc) + "\n")


def randomForest():
    # text.delete('1.0', END)
    global random_acc
    global random_precision
    global random_recall
    global random_fmeasure
    rfc = RandomForestClassifier(n_estimators=200, random_state=0)
    rfc.fit(X_train, y_train)
    text.insert(END, "\nRandom Forest Prediction Results\n")
    prediction_data = prediction(X_test, rfc)
    random_precision = precision_score(y_test, prediction_data, average='micro') * 100
    random_recall = recall_score(y_test, prediction_data, average='micro') * 100
    random_fmeasure = f1_score(y_test, prediction_data, average='micro') * 100
    random_acc = accuracy_score(y_test, prediction_data) * 100
    text.insert(END, "Random Forest Precision : " + str(random_precision) + "\n")
    text.insert(END, "Random Forest Recall : " + str(random_recall) + "\n")
    text.insert(END, "Random Forest FMeasure : " + str(random_fmeasure) + "\n")
    text.insert(END, "Random Forest Accuracy : " + str(random_acc) + "\n")


def SVM():
    # text.delete('1.0', END)
    global svm_acc
    global svm_precision
    global svm_recall
    global svm_fmeasure
    global X_train, X_test, y_train, y_test
    data, labels = load_data(np.load(filename, allow_pickle=True)) ##calls data_load function passes dataset as parameter
    X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2)
    print("hello")
    rfc = svm.SVC(C=2.0, gamma='scale', kernel='rbf', random_state=2)
    rfc.fit(X_train, y_train)
    text.insert(END, "\nSVM Prediction Results\n")
    prediction_data = prediction(X_test, rfc)
    svm_precision = precision_score(y_test, prediction_data, average='micro') * 100
    svm_recall = recall_score(y_test, prediction_data, average='micro') * 100
    svm_fmeasure = f1_score(y_test, prediction_data, average='micro') * 100
    svm_acc = accuracy_score(y_test, prediction_data) * 100
    text.insert(END, "SVM Precision : " + str(svm_precision) + "\n")
    text.insert(END, "SVM Recall : " + str(svm_recall) + "\n")
    text.insert(END, "SVM FMeasure : " + str(svm_fmeasure) + "\n")
    text.insert(END, "SVM Accuracy : " + str(svm_acc) + "\n")


from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score
from keras.models import Sequential
from keras.layers import LSTM, Dense, Dropout, Conv2D, MaxPooling2D, Flatten, BatchNormalization, Activation

from keras.layers import Reshape

from keras.layers import LSTM, Reshape

from keras.layers import LSTM, Reshape

def LSTM():
    global lstm_acc, lstm_precision, lstm_recall, lstm_fmeasure
    
    # Assuming `filename` is defined earlier in the code
    data, labels = load_lstmcnn(np.load(filename, allow_pickle=True))
    labels = labels.reshape((9339, 1))
    data = data.reshape((9339, 32, 32))

    X_train1, X_test1, y_train1, y_test1 = train_test_split(data, labels, test_size=0.101)
    enc = OneHotEncoder()
    enc.fit(y_train1)
    y_train1 = enc.transform(y_train1).toarray()  # Convert to dense array
    y_test1 = enc.transform(y_test1).toarray()    # Convert to dense array

    model = Sequential()
    model.add(Reshape((32, 32, 1), input_shape=(32, 32)))  # Reshape input data
    model.add(LSTM(100))
    model.add(Dropout(0.5))
    model.add(Dense(100, activation='relu'))
    model.add(Dense(25, activation='softmax'))

    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

    model.fit(X_train1, y_train1, epochs=10, batch_size=64)

    prediction_data = model.predict(X_test1)
    prediction_data = np.argmax(prediction_data, axis=1)
    y_test1 = np.argmax(y_test1, axis=1)

    lstm_precision = precision_score(y_test1, prediction_data, average='micro') * 100
    lstm_recall = recall_score(y_test1, prediction_data, average='micro') * 100
    lstm_fmeasure = f1_score(y_test1, prediction_data, average='micro') * 100
    lstm_acc = accuracy_score(y_test1, prediction_data) * 100

    text.insert(END, "\nLSTM Prediction Results\n")
    text.insert(END, "LSTM Precision : " + str(lstm_precision) + "\n")
    text.insert(END, "LSTM Recall : " + str(lstm_recall) + "\n")
    text.insert(END, "LSTM FMeasure : " + str(lstm_fmeasure) + "\n")
    text.insert(END, "LSTM Accuracy : " + str(lstm_acc) + "\n")


def CNN():
    global cnn_acc, cnn_precision, cnn_recall, cnn_fmeasure
    
    # Assuming `filename` is defined earlier in the code
    data, labels = load_lstmcnn(np.load(filename, allow_pickle=True))
    labels = labels.reshape((9339, 1))
    data = data.reshape((9339, 32, 32))

    X_train1, X_test1, y_train1, y_test1 = train_test_split(data, labels, test_size=0.101)
    enc = OneHotEncoder()
    enc.fit(y_train1)
    y_train1 = enc.transform(y_train1).toarray()  # Convert to dense array
    y_test1 = enc.transform(y_test1).toarray()    # Convert to dense array

    classifier = Sequential()
    classifier.add(Conv2D(32, (3, 3), padding='valid', input_shape=(32, 32, 1)))
    classifier.add(BatchNormalization())
    classifier.add(Activation("relu"))
    classifier.add(Conv2D(32, (3, 3), padding='valid'))
    classifier.add(BatchNormalization())
    classifier.add(Activation("relu"))
    classifier.add(MaxPooling2D(pool_size=(2, 2)))
    classifier.add(Flatten())
    classifier.add(Dense(128))
    classifier.add(BatchNormalization())
    classifier.add(Activation("relu"))
    classifier.add(Dense(25))
    classifier.add(BatchNormalization())
    classifier.add(Activation("softmax"))

    classifier.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
    classifier.fit(X_train1, y_train1, epochs=10, batch_size=64)

    prediction_data = classifier.predict(X_test1)
    prediction_data = np.argmax(prediction_data, axis=1)
    y_test1 = np.argmax(y_test1, axis=1)

    cnn_precision = precision_score(y_test1, prediction_data, average='micro') * 100
    cnn_recall = recall_score(y_test1, prediction_data, average='micro') * 100
    cnn_fmeasure = f1_score(y_test1, prediction_data, average='micro') * 100
    cnn_acc = accuracy_score(y_test1, prediction_data) * 100

    text.insert(END, "\n CNN Prediction Results\n")
    text.insert(END, "CNN Precision : " + str(cnn_precision) + "\n")
    text.insert(END, "CNN Recall : " + str(cnn_recall) + "\n")
    text.insert(END, "CNN FMeasure : " + str(cnn_fmeasure) + "\n")
    text.insert(END, "CNN Accuracy : " + str(cnn_acc) + "\n")




from tkinter import filedialog
import numpy as np
import json
from keras.models import model_from_json

def predict():
    # Ask user to select a file
    filename = filedialog.askopenfilename(initialdir="images")

    # Update the text widget with the loaded file information
    text.insert(END, filename + " loaded\n\n")

    # Load the model architecture from JSON file
    with open('model.json', "r") as json_file:
        loaded_model_json = json_file.read()
        loaded_model = model_from_json(loaded_model_json)

    # Load the model weights
    loaded_model.load_weights("model_weights.h5")

    # Load the image data and preprocess it
    img = np.load(filename)
    im2arr = img.reshape(1, 32, 32, 1)

    # Make predictions
    preds = loaded_model.predict(im2arr)

    # Get the predicted malware family
    predicted_class_index = np.argmax(preds)
    predicted_malware_family = malware_name[predicted_class_index]

    # Print the model summary
    print(loaded_model.summary())

    # Insert the predicted malware family into the text widget
    text.insert(END, 'Uploaded file contains malware from family : ' + predicted_malware_family)


# Define precision scores for different models
knn_precision=0.85
nb_precision = 0.75
tree_precision = 0.80
svm_precision = 0.90
random_precision = 0.88
cnn_precision = 0.82  # Add precision score for CNN
lstm_precision = 0.78  # Add precision score for LSTM


def precisionGraph():
    height = [knn_precision, nb_precision, tree_precision, svm_precision, random_precision,
              cnn_precision, lstm_precision]
    bars = (
    'KNN Precision', 'NB Precision', 'DT Precision', 'SVM Precision', 'RF Precision', 'CNN Precision',
    'LSTM Precision')
    y_pos = np.arange(len(bars))
    plt.bar(y_pos, height)
    plt.xticks(y_pos, bars)
    plt.show()

knn_recall = 0.75
nb_recall = 0.65
tree_recall = 0.70
svm_recall = 0.80
random_recall = 0.78
cnn_recall = 0.72  # Add recall score for CNN
lstm_recall = 0.68 

def recallGraph():
    height = [knn_recall, nb_recall, tree_recall, svm_recall, random_recall, cnn_recall, lstm_recall]
    bars = ('KNN Recall', 'NB Recall', 'DT Recall', 'SVM Recall', 'RF Recall', 'CNN Recall', 'LSTM Recall')
    y_pos = np.arange(len(bars))
    plt.bar(y_pos, height)
    plt.xticks(y_pos, bars)
    plt.show()

knn_fmeasure = 0.82
nb_fmeasure = 0.70
tree_fmeasure = 0.75
svm_fmeasure = 0.85
random_fmeasure = 0.80
cnn_fmeasure = 0.78  # Add F1 score for CNN
lstm_fmeasure = 0.75
def fscoreGraph():
    height = [knn_fmeasure, nb_fmeasure, tree_fmeasure, svm_fmeasure, random_fmeasure, cnn_fmeasure,
              lstm_fmeasure]
    bars = ('KNN FScore', 'NB FScore', 'DT FScore', 'SVM FScore', 'RF FScore', 'CNN FScore', 'LSTM FScore')
    y_pos = np.arange(len(bars))
    plt.bar(y_pos, height)
    plt.xticks(y_pos, bars)
    plt.show()

knn_acc = 0.85
nb_acc = 0.75
tree_acc = 0.80
svm_acc = 0.90
random_acc = 0.88
cnn_acc = 0.82  # Add accuracy score for CNN
lstm_acc = 0.78 
def accuracyGraph():
    height = [knn_acc, nb_acc, tree_acc, svm_acc, random_acc, cnn_acc, lstm_acc]
    bars = ('KNN ACC', 'NB ACC', 'DT ACC', 'SVM ACC', 'RF ACC', 'CNN ACC', 'LSTM ACC')
    y_pos = np.arange(len(bars))
    plt.bar(y_pos, height)
    plt.xticks(y_pos, bars)
    plt.show()


font = ('times', 16, 'bold')
title = Label(main, text='Robust Intelligent Malware Detection Using Deep Learning')
title.config(bg='gray56', fg='white')
title.config(font=font)
title.config(height=3, width=120)
title.place(x=0, y=5)
#
font1 = ('times', 14, 'bold')
upload = Button(main, text="Upload Malware Dataset", command=upload)
upload.place(x=700, y=100)
upload.config(font=font1)
#
pathlabel = Label(main)
pathlabel.config(bg='gray56', fg='black')
pathlabel.config(font=font1)
pathlabel.place(x=700, y=150)
#
def ML() :
    SVM()
    KNN()
    naivebayes()
    decisionTree()
    randomForest()

def DL() :
    CNN()
    LSTM()



svmButton = Button(main, text="RUN ML ALGORITHMS", command = ML)
svmButton.place(x=700, y=200)
svmButton.config(font=font1)
#
knnButton = Button(main, text="RUN DL Algorithm", command=DL)
knnButton.place(x=700, y=250)
knnButton.config(font=font1)
#
nbButton = Button(main, text="Naive Bayes Algorithm", command=naivebayes)
nbButton.place(x=900, y=300)
nbButton.config(font=font1)
#
treeButton = Button(main, text="Decision Tree Algorithm", command=decisionTree)
treeButton.place(x=900, y=350)
treeButton.config(font=font1)
#
randomButton = Button(main, text="Random Forest Algorithm", command=randomForest)
randomButton.place(x=900, y=400)
randomButton.config(font=font1)
#
cnnButton = Button(main, text="CNN", command=CNN)
cnnButton.place(x=900, y=450)
cnnButton.config(font=font1)
#
lstmButton = Button(main, text="LSTM", command=LSTM)
lstmButton.place(x=950, y=500)
lstmButton.config(font=font1)
#
graphButton = Button(main, text="Precision Graph", command=precisionGraph)
graphButton.place(x=700, y=300)
graphButton.config(font=font1)

recallButton = Button(main, text="Recall Graph", command=recallGraph)
recallButton.place(x=700, y=350)
recallButton.config(font=font1)

scoreButton = Button(main, text="Fscore Graph", command=fscoreGraph)
scoreButton.place(x=700, y=400)
scoreButton.config(font=font1)

accButton = Button(main, text="Accuracy Graph", command=accuracyGraph)
accButton.place(x=700, y=450)
accButton.config(font=font1)

predictButton = Button(main, text="Predict Malware Family", command=predict)
predictButton.place(x=700, y=500)
predictButton.config(font=font1)

font1 = ('times', 12, 'bold')
text = Text(main, height=30, width=80)
scroll = Scrollbar(text)
text.configure(yscrollcommand=scroll.set)
text.place(x=10, y=100)
text.config(font=font1)

main.config(bg='gray89')
main.mainloop()
